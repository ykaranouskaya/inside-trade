# !usr/bin/python

import argparse
import sys
import csv
import json
from pathlib import Path
import logging

from insider_trading.market_api import API
from insider_trading.utils import to_date, check_days_diff


MAX_QUEUE_LEN = 500
DATE_WINDOW = 180

LOG = logging.getLogger(__name__)
LOG.setLevel('INFO')


def parse_arguments(argv):
    parser = argparse.ArgumentParser()
    parser.add_argument('--database', type=Path, help='Database .csv file with SEC forms info.')
    parser.add_argument('--output_folder', type=Path, help='Path to the output folder with market data.')
    parser.add_argument('--api_function', type=str, default='TIME_SERIES_WEEKLY_ADJUSTED',
                        help='Type of market data to download.')
    parser.add_argument('--output_size', type=str, default=None,
                        help='If `api_function` is DAILY, need to specify output size '
                        '(compact / full).')
    parser.add_argument('--verbose', '-v', action='store_true', default=False, help='Show debug messages')
    return parser.parse_args(argv)


def is_out_of_date(date, last_refreshed):
    date = to_date(date)
    last_refreshed = to_date(last_refreshed)

    return check_days_diff(date, last_refreshed, diff=DATE_WINDOW)


def need_update(ticker, date, output_folder):
    """
    Check if ticker data already exist and up to date.
    :param ticker:
    :param output_folder:
    :return: Tuple (bool, data)
    """
    json_path = output_folder / (ticker + '.json')
    if not json_path.exists():
        return True, None

    with open(json_path, 'r') as fin:
        data = json.load(fin)
        try:
            last_refreshed = data['Meta Data']['3. Last Refreshed']
        except KeyError:
            LOG.warning(f"File {json_path} has invalid format.")
            return True, None

    if is_out_of_date(date, last_refreshed):
        return True, data

    LOG.debug(f"Stock {ticker} is up to date, skipping.")
    return False


def prepare_symbols(database, output_folder):
    """
    Read database and find 50 unique symbols that need to be updated.
    :param database: csv file to read SEC data.
    :param output_folder: Path, folder where ticket data is saved.
    :return: list of symbols to download
    """
    symbols = set()
    # Read database line by line and check ticker
    with open(database, 'r') as fin:
        csv_reader = csv.DictReader(fin)
        for row in csv_reader:
            ticker = row['TICKER']
            ticker = ticker.upper()
            date = row['REPORT_DATE']

            if ticker not in symbols and need_update(ticker, date, output_folder):
                symbols.add(ticker)
            if len(symbols) == MAX_QUEUE_LEN:
                break

    return list(symbols)


def main(argv=None):
    argv = argv or sys.argv[1:]
    args = parse_arguments(argv)

    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format='%(name)s - %(levelname)s - %(message)s')

    symbols = prepare_symbols(args.database, args.output_folder)
    LOG.info(f'START DOWNLOADING MARKET DATA FOR: {symbols}')
    market_api = API(args.api_function, args.output_size)

    data = market_api.get_symbols_data(symbols[:2])
    for entry in data:
        info = entry['Meta Data']['2. Symbol']
        filename = Path(args.output_folder) / (info + '.json')
        with open(filename, 'w') as fout:
            json.dump(entry, fout)
        LOG.info(f'Saved {info} market data to {filename}.')

    LOG.info('DONE.')


if __name__ == '__main__':
    main()
